<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>FIPER: Generalizable Factorized Fields for Joint Image Compression and Super-Resolution</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jayisaking.github.io/FIPER/img/SRConceptual.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1711">
    <meta property="og:image:height" content="576">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jayisaking.github.io/FIPER/" />
    <meta property="og:title" content="FIPER: Generalizable Factorized Fields for Joint Image Compression and Super-Resolution" />
    <meta property="og:description"
        content="In this work, we propose a unified representation for Super-Resolution (SR) and Image Compression, termed Factorized Fields, motivated by the shared principles between these two tasks. Both SISR and Image Compression require recovering and preserving fine image detailsâ€”whether by enhancing resolution or reconstructing compressed data. Unlike previous methods that mainly focus on network architecture, our proposed approach utilizes a basis-coefficient decomposition to explicitly capture multi-scale visual features and structural components in images, addressing the core challenges of both tasks. We first derive our SR model, which includes a Coefficient Backbone and Basis Swin Transformer for generalizable Factorized Fields. Then, to further unify these two tasks, we leverage the strong information-recovery capabilities of the trained SR modules as priors in the compression pipeline, improving both compression efficiency and detail reconstruction. Additionally, we introduce a merged-basis compression branch that consolidates shared structures, further optimizing the compression process. Extensive experiments show that our unified representation delivers state-of-the-art performance, achieving an average relative improvement of 204.4% in PSNR over the baseline in Super-Resolution (SR) and 9.35% BD-rate reduction in Image Compression compared to the previous SOTA." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="FIPER: Generalizable Factorized Fields for Joint Image Compression and Super-Resolution" />
    <meta name="twitter:description"
        content="In this work, we propose a unified representation for Super-Resolution (SR) and Image Compression, termed Factorized Fields, motivated by the shared principles between these two tasks. Both SISR and Image Compression require recovering and preserving fine image detailsâ€”whether by enhancing resolution or reconstructing compressed data. Unlike previous methods that mainly focus on network architecture, our proposed approach utilizes a basis-coefficient decomposition to explicitly capture multi-scale visual features and structural components in images, addressing the core challenges of both tasks. We first derive our SR model, which includes a Coefficient Backbone and Basis Swin Transformer for generalizable Factorized Fields. Then, to further unify these two tasks, we leverage the strong information-recovery capabilities of the trained SR modules as priors in the compression pipeline, improving both compression efficiency and detail reconstruction. Additionally, we introduce a merged-basis compression branch that consolidates shared structures, further optimizing the compression process. Extensive experiments show that our unified representation delivers state-of-the-art performance, achieving an average relative improvement of 204.4% in PSNR over the baseline in Super-Resolution (SR) and 9.35% BD-rate reduction in Image Compression compared to the previous SOTA." />
    <meta name="twitter:image" content="https://jayisaking.github.io/FIPER/img/SRConceptual.jpg" />

    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8ZERS5BVPS"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-8ZERS5BVPS');
    </script>   
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/synced_video_selector.js"></script>

    <script type="module">
        import { createSplatView, setSplatScene, setupCarousel } from "./js/splats.js"
        setupCarousel(createSplatView("splat-picker"), document.querySelector("#splat-carousel"));
    </script>
    <style>
        .final-element {
            white-space: nowrap;
        }
    </style>
</head>

<body style="padding: 5%; padding-top: min(15px, 5%); padding-bottom: min(5px, 5%); width: 100%">
    <div class="container-lg text-center" style="max-width: 1500px; margin: auto;" id="main">
        <header role="banner">
            <!-- <div class="container" id="main"> -->
            <div class="row">
                <h2 class="col-md-12 text-center">
                    <b>FIPER:</b> Generalizable Factorized Fields for Joint Image Compression and Super-Resolution</br>
                </h2>
            </div>
            <div class="row text-center">
                <div class="col-md-3">
                </div>
                <div class="container-fluid text-center">
                    <ul class="list-inline" style="white-space: nowrap; margin:0px 0px 0px 0px;" >
                        <li><a style="font-size: calc(min(3vw, 15px))" href="">Yang-Che SunÂ¹</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="">Cheng Yu YeoÂ¹</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="https://www.cs.jhu.edu/~schu23/">Ernie ChuÂ²</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng ChenÂ³</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))"  href="https://yulunalexliu.github.io/">Yu-Lun LiuÂ¹</a></li>
                    </ul>
                </div>
                <div class="col-md-12 text-center" style="font-size: calc(min(3vw, 15px))">
            Â¹National Yang Ming Chiao Tung University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Â²Johns Hopkins University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Â³Academia Sinica
                </div>
            </div>
            <div class="row text-center">
                <span class="link-block" style="padding-top: 10px; padding-bottom: 10px">
                    <a href="https://arxiv.org/abs/2410.18083" class="external-link button is-normal is-rounded is-dark"
                        style="width: 80px; font-size: 15px">
                        <span class="icon">
                            <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                    </a>
                    <a href="" class="external-link button is-normal is-rounded is-dark"
                        style="width: 190px; font-size: 15px">
                        <span class="icon">
                            <i class="far fa-file-code"></i>
                        </span>
                        <span>Code [coming soon]</span>
                    </a>
                </span>
            </div>
        </header>

        <main role="main">
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Abstract </h3>
                    <p class="text-justify" style="text-align: left;">
    In this work, we propose a unified representation for Super-Resolution (SR) and Image Compression, termed <b>Factorized Fields</b>, motivated by the shared principles between these two tasks. Both SISR and Image Compression require recovering and preserving fine image detailsâ€”whether by enhancing resolution or reconstructing compressed data. Unlike previous methods that mainly focus on network architecture, our proposed approach utilizes a basis-coefficient decomposition to explicitly capture multi-scale visual features and structural components in images, addressing the core challenges of both tasks. We first derive our SR model, which includes a Coefficient Backbone and Basis Swin Transformer for generalizable Factorized Fields. Then, to further unify these two tasks, we leverage the strong information-recovery capabilities of the trained SR modules as priors in the compression pipeline, improving both compression efficiency and detail reconstruction. Additionally, we introduce a merged-basis compression branch that consolidates shared structures, further optimizing the compression process. Extensive experiments show that our unified representation delivers state-of-the-art performance, achieving an average relative improvement of 204.4% in PSNR over the baseline in Super-Resolution (SR) and 9.35% BD-rate reduction in Image Compression compared to the previous SOTA.
                    </p>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2 rounded" style="text-align: center; padding-bottom: 0px; padding-top: 5px; background-color: #d0d5ec;">
                    <h6 style="text-align: center; color:rgb(0, 0, 0)"><strong>TL;DR</strong>: A new unified representation for both super-resolution and image compression.</h6>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> The correlation between coordinate transformation and downsampling </h3>
                    <image width=60% src="img/pixel_sampling_pptx_v4.jpg"
                        alt="A diagram explaining the method in broad strokes, like explained in the caption."></image>

                    <figcaption class="text-justify margin-5" style="text-align: left;">
                    (a) The sawtooth transformation example with \(k=2\). (b) The PixelUnShuffle downsample. (c) To explicitly model the information for sampling with a sawtooth, we rearrange the feature map in a dilation-like manner in the downsample layer of the Basis Swin Transformer. This way, the feature sampled would capture the information in the original layout correctly.
                    </p>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> The overall pipeline of image super-resolution with our Factorized Fields </h3>
                    <image width=100% src="img/SRConceptual.jpg"
                        alt="A diagram explaining the method in broad strokes, like explained in the caption."></image>

                    <figcaption class="text-justify margin-5" style="text-align: left; margin-top:-20px;">
                    Given a low-resolution image \(I_{LR}\), we first extract coefficient feature map \(X_\text{coeff}\) with the coefficient backbone, which is then decoded into coefficient and passed through the basis Swin Transformer for basis, separately. Finally, the coefficient and basis are sampled, multiplied, and decoded for final high-resolution output \(I_{HR}\), where \(s\), \(H\), \(W\) denote the scale factor, height, and width respectively.
                    </p>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> The illustration of our joint image-compression and super-resolution framework compared with the traditional compression-only method </h3>
                    <image width=100% src="img/Compression_SR-ICLR.jpg"
                        alt="A diagram explaining the method in broad strokes, like explained in the caption."></image>

                    <figcaption class="text-justify margin-5" style="text-align: left;">
                    (a) Traditional learning-based compression methods. (b) Our approach surpasses (a) by incorporating our Super-Resolution (SR) Module as information-recovery prior. (c) Expanding on (b) and introducing a multi-image compression strategy that utilizes both our SR Module and a Basis Merging Transformer to capture shared structure.
                    </p>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Visual comparisons on super-resolution (4Ã—) </h3>
                    <image width=80% src="img/exp_SR_Fiper_Visualization.jpg"
                        alt="A diagram explaining the method in broad strokes, like explained in the caption."></image>
                    </p>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Performance (RD-Curve) evaluation on image compression using different datasets </h3>
                    <image width=100% src="img/IC.jpg"
                        alt="A diagram explaining the method in broad strokes, like explained in the caption."></image>
                    </p>
                </div>
            </div><br>

            <div class="col-md-8 offset-md-2 text-start">
                <h4>
                    Acknowledgements
                </h4>

                <p class="text-justify" style="text-align: left;">
                    This research was funded by the National Science and Technology Council, Taiwan, under Grants NSTC 112-2222-E-A49-004-MY2 and 113-2628-E-A49-023-. The authors are grateful to Google, NVIDIA, and MediaTek Inc. for generous donations. Yu-Lun Liu acknowledges the Yushan Young Fellow Program by the MOE in Taiwan.
                    <br><br><br>
                </p>
            </div>
            <div class="row justify-content-center">
                <div class="col-md-5 center text-start">
                    <label style="display: inline" for="bibtex">
                        <h4 style="text-align: center">BibTeX </h4>
                    </label>
                    <textarea id="bibtex" class="form-control" readonly>
@article{sun2024fiper,
    title={FIPER: Generalizable Factorized Fields for Joint Image Compression and Super-Resolution},
    author={Yang-Che Sun and Cheng Yu Yeo and Ernie Chu and Jun-Cheng Chen and Yu-Lun Liu},
    journal={arXiv},
    year={2024}
}
                        </textarea>
                </div>
            </div>


        </main>
        <footer>
            <div class="row">
                <div class="col-md-8 offset-md-2 text-start">

                    <p class="text-justify" style="text-align: left;">
                        <i>
                            The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a>,
                            <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>, and <a
                                href="https://reconfusion.github.io">ReconFusion</a>.
                        </i>
                    </p>
                </div>
            </div>

        </footer>
    </div>
</body>

</html>
