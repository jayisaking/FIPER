<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>FIPER: Factorized Features for Robust Image Super-Resolution and Compression</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jayisaking.github.io/FIPER/img/SRConceptual.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1711">
    <meta property="og:image:height" content="576">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jayisaking.github.io/FIPER/" />
    <meta property="og:title" content="FIPER: Factorized Features for Robust Image Super-Resolution and Compression" />
    <meta property="og:description"
        content="In this work, we propose a unified representation for Super-Resolution (SR) and Image Compression, termed Factorized Fields, motivated by the shared principles between these two tasks. Both SISR and Image Compression require recovering and preserving fine image detailsâ€”whether by enhancing resolution or reconstructing compressed data. Unlike previous methods that mainly focus on network architecture, our proposed approach utilizes a basis-coefficient decomposition to explicitly capture multi-scale visual features and structural components in images, addressing the core challenges of both tasks. We first derive our SR model, which includes a Coefficient Backbone and Basis Swin Transformer for generalizable Factorized Fields. Then, to further unify these two tasks, we leverage the strong information-recovery capabilities of the trained SR modules as priors in the compression pipeline, improving both compression efficiency and detail reconstruction. Additionally, we introduce a merged-basis compression branch that consolidates shared structures, further optimizing the compression process. Extensive experiments show that our unified representation delivers state-of-the-art performance, achieving an average relative improvement of 204.4% in PSNR over the baseline in Super-Resolution (SR) and 9.35% BD-rate reduction in Image Compression compared to the previous SOTA." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="FIPER: Factorized Features for Robust Image Super-Resolution and Compression" />
    <meta name="twitter:description"
        content="In this work, we propose a unified representation for Super-Resolution (SR) and Image Compression, termed Factorized Fields, motivated by the shared principles between these two tasks. Both SISR and Image Compression require recovering and preserving fine image detailsâ€”whether by enhancing resolution or reconstructing compressed data. Unlike previous methods that mainly focus on network architecture, our proposed approach utilizes a basis-coefficient decomposition to explicitly capture multi-scale visual features and structural components in images, addressing the core challenges of both tasks. We first derive our SR model, which includes a Coefficient Backbone and Basis Swin Transformer for generalizable Factorized Fields. Then, to further unify these two tasks, we leverage the strong information-recovery capabilities of the trained SR modules as priors in the compression pipeline, improving both compression efficiency and detail reconstruction. Additionally, we introduce a merged-basis compression branch that consolidates shared structures, further optimizing the compression process. Extensive experiments show that our unified representation delivers state-of-the-art performance, achieving an average relative improvement of 204.4% in PSNR over the baseline in Super-Resolution (SR) and 9.35% BD-rate reduction in Image Compression compared to the previous SOTA." />
    <meta name="twitter:image" content="https://jayisaking.github.io/FIPER/img/SRConceptual.jpg" />

    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8ZERS5BVPS"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-8ZERS5BVPS');
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/synced_video_selector.js"></script>

    <script type="module">
        import { createSplatView, setSplatScene, setupCarousel } from "./js/splats.js"
        setupCarousel(createSplatView("splat-picker"), document.querySelector("#splat-carousel"));
    </script>
    <style>
        .final-element {
            white-space: nowrap;
        }
    </style>
</head>

<body style="padding: 5%; padding-top: min(15px, 5%); padding-bottom: min(5px, 5%); width: 100%">
    <div class="container-lg text-center" style="max-width: 1500px; margin: auto;" id="main">
        <header role="banner">
            <!-- <div class="container" id="main"> -->
            <div class="row">
                <h2 class="col-md-12 text-center">
                    <b>FIPER:</b> Factorized Features for Robust Image Super-Resolution and Compression</br>
                </h2>
            </div>
            <div class="row text-center">
                <div class="col-md-3">
                </div>
                <div class="container-fluid text-center">
                    <ul class="list-inline" style="white-space: nowrap; margin:0px 0px 0px 0px;">
                        <li><a style="font-size: calc(min(3vw, 15px))" href="">Yang-Che SunÂ¹</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="">Cheng Yu YeoÂ¹</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="https://www.cs.jhu.edu/~schu23/">Ernie
                                ChuÂ²</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))"
                                href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng
                                ChenÂ³</a></li>
                        <li><a style="font-size: calc(min(3vw, 15px))" href="https://yulunalexliu.github.io/">Yu-Lun
                                LiuÂ¹</a></li>
                    </ul>
                </div>
                <div class="col-md-12 text-center" style="font-size: calc(min(3vw, 15px))">
                    Â¹National Yang Ming Chiao Tung University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Â²Johns Hopkins
                    University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Â³Academia Sinica
                </div>
            </div>
            <div class="row text-center">
                <span class="link-block" style="padding-top: 10px; padding-bottom: 10px">
                    <a href="https://arxiv.org/abs/2410.18083" class="external-link button is-normal is-rounded is-dark"
                        style="width: 80px; font-size: 15px">
                        <span class="icon">
                            <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                    </a>
                    <a href="" class="external-link button is-normal is-rounded is-dark"
                        style="width: 190px; font-size: 15px">
                        <span class="icon">
                            <i class="far fa-file-code"></i>
                        </span>
                        <span>Code [coming soon]</span>
                    </a>
                </span>
            </div>
        </header>

        <main role="main">
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Abstract </h3>
                    <p class="text-justify" style="text-align: left;">
                        In this work, we propose using a unified representation, termed <b>Factorized Features</b>, for low-level vision tasks, where we test on <b>Single Image Super-Resolution (SISR)</b> and <b>Image Compression</b>. Motivated by the shared principles between these tasks, they require recovering and preserving fine image details, whether by enhancing resolution for SISR or reconstructing compressed data for Image Compression. Unlike previous methods that mainly focus on network architecture, our proposed approach utilizes a basis-coefficient decomposition as well as an explicit formulation of frequencies to capture structural components and multi-scale visual features in images, which addresses the core challenges of both tasks. We replace the representation of prior models from simple feature maps with Factorized Features to validate the potential for broad generalizability. In addition, we further optimize the compression pipeline by leveraging the mergeable-basis property of our Factorized Features, which consolidates shared structures on multi-frame compression. Extensive experiments show that our unified representation delivers state-of-the-art performance, achieving an average relative improvement of 204.4% in PSNR over the baseline in Super-Resolution (SR) and 9.35% BD-rate reduction in Image Compression compared to the previous SOTA.
                    </p>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2 rounded"
                    style="text-align: center; padding-bottom: 0px; padding-top: 5px; background-color: #d0d5ec;">
                    <h6 style="text-align: center; color:rgb(0, 0, 0)"><strong>TL;DR</strong>: An unified image representation to reconstruct the fine details.</h6>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Comparison between decomposition-based, architecture-based, and our Factorized Features representation </h3>

                    <image width=100% src="img/comparison-teaser.png"
                        alt="A comparison illustrating decomposition-based methods, architecture-driven approaches, and our factorized representation."></image>

                    <figcaption class="text-justify margin-5" style="text-align: left;">
                        (a) Prior decomposition-based methods use fixed Fourier- or wavelet-like bases to capture periodic structures, but often fail to preserve high-fidelity textures.  
                        (b) Architecture-oriented approaches enhance model depth or attention mechanisms, yet lack explicit frequency modeling and thus struggle with repetitive patterns.  
                        (c) Our method introduces learned Factorized Features with generalizable basisâ€“coefficient decomposition, enabling accurate reconstruction of both global structure and local periodic patterns.  
                        Pixel-importance visualizations (middle row) illustrate that our approach focuses more effectively on structurally meaningful regions.
                    </figcaption>
                </div>
            </div>

            <br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> The full Factorized Features formulation </h3>

                    <image width=100% src="img/factorized-features.png"
                        alt="Diagram illustrating coordinate transformation and multi-frequency modulation in Factorized Features."></image>

                    <figcaption class="text-justify margin-5" style="text-align: left;">
                        This figure visualizes our complete representation defined in Eq. (7) and (8):  
                        \[
                            \hat{I}(x) = 
                            P\!\left(
                                \text{Concat}_{i=1}^{N}
                                \text{Concat}_{j=1}^{K}
                                \left[
                                    c_{ij}(x)\,\odot\,
                                    \psi\!\left(\alpha_j \cdot b_i(\gamma_i(x))\right)
                                \right]
                            \right).
                        \]
                        The sawtooth coordinate transform \(\gamma_i(x)\) enforces explicit periodic sampling, causing each basis \(b_i\) to repeat at controlled spatial intervals.  
                        Multi-frequency scaling \(\alpha_j\) modulates every basis with both low- and high-frequency responses, while \(\psi\) provides a nonlinear periodic mapping that encourages sharper oscillations.  
                        By combining spatially varying coefficients \(c_{ij}(x)\) with frequency-modulated and transformed bases, the formulation captures fine textures, repetitive patterns, and multi-scale structures essential for Super-Resolution and Image Compression.
                    </figcaption>
                </div>
            </div>

            <br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Super-Resolution and Image Compression with Factorized Features </h3>

                    <image width=100% src="img/sr-and-ic-arch.png"
                        alt="Pipeline diagrams of Factorized Features applied to Super-Resolution and Image Compression."></image>

                    <figcaption class="text-justify margin-5" style="text-align: left;">
                        <b>(a)</b> In Super-Resolution, the low-resolution input is processed by the Coefficient Backbone to extract \(X_{\text{coeff}}\).  
                        From this shared feature representation, convolution layers generate spatially varying coefficients, while the Basis Swin Transformer produces a multi-scale set of basis maps.  
                        The final output is reconstructed through the Factorized Features formulation, enabling explicit modeling of high- and low-frequency components.  
                        <br><br>
                        <b>(b)</b> For Image Compression, the synthesis transform of a learned compression model is replaced with our SR module.  
                        This design leverages SR priors and the structured basisâ€“coefficient representation to restore details more effectively after quantization, reducing distortion at comparable bitrates.
                    </figcaption>
                </div>
            </div>
            <br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Visual comparisons on super-resolution (4Ã—) </h3>
                    <image width=80% src="img/exp_SR_Fiper_Visualization.jpg"
                        alt="A diagram explaining the method in broad strokes, like explained in the caption."></image>
                    </p>
                </div>
            </div><br>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <h3> Performance (RD-Curve) evaluation on image compression using different datasets </h3>
                    <image width=100% src="img/IC.jpg"
                        alt="A diagram explaining the method in broad strokes, like explained in the caption."></image>
                    </p>
                </div>
            </div><br>

            <div class="col-md-8 offset-md-2 text-start">
                <h4>
                    Acknowledgements
                </h4>

                <p class="text-justify" style="text-align: left;">
                    This research was funded by the National Science and Technology Council, Taiwan, under Grants NSTC
                    112-2222-E-A49-004-MY2 and 113-2628-E-A49-023-. The authors are grateful to Google, NVIDIA, and
                    MediaTek Inc. for generous donations. Yu-Lun Liu acknowledges the Yushan Young Fellow Program by the
                    MOE in Taiwan.
                    <br><br><br>
                </p>
            </div>
            <div class="row justify-content-center">
                <div class="col-md-5 center text-start">
                    <label style="display: inline" for="bibtex">
                        <h4 style="text-align: center">BibTeX </h4>
                    </label>
                    <textarea id="bibtex" class="form-control" readonly>
@inproceedings{
sun2025fiper,
title={{FIPER}: Factorized Features for Robust Image Super-Resolution and Compression},
author={Yang-Che Sun and Cheng Yu Yeo and Ernie Chu and Jun-Cheng Chen and Yu-Lun Liu},
booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
year={2025},
url={https://openreview.net/forum?id=gcrDTxZTl0}
}
                    </textarea>
                </div>
            </div>


        </main>
        <footer>
            <div class="row">
                <div class="col-md-8 offset-md-2 text-start">

                    <p class="text-justify" style="text-align: left;">
                        <i>
                            The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a>,
                            <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>, and <a
                                href="https://reconfusion.github.io">ReconFusion</a>.
                        </i>
                    </p>
                </div>
            </div>

        </footer>
    </div>
</body>

</html>